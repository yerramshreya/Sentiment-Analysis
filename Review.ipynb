{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e22cf8",
   "metadata": {},
   "source": [
    "# 1. Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0930723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,SparseCategoricalCrossentropy,mse\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e48ed",
   "metadata": {},
   "source": [
    "# 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f18c8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13617</th>\n",
       "      <td>where would one start a review of the film Sni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20108</th>\n",
       "      <td>Scenarist Frederick Fox's sometimes memorable ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "13617  where would one start a review of the film Sni...  positive\n",
       "20108  Scenarist Frederick Fox's sometimes memorable ...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\aredd\\Downloads\\IMDB Dataset.csv\\IMDB Dataset.csv\")\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45e26c",
   "metadata": {},
   "source": [
    "# 3. Data Outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459a1393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values\n",
      " review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "\n",
      " \t Review Balance count\n",
      " Counter({1: 25000, 0: 25000})\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>Lame rip-off of THE QUATERMASS XPERIMENT (1955...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16680</th>\n",
       "      <td>This is a 100% improvement over the dross of a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "1097   Lame rip-off of THE QUATERMASS XPERIMENT (1955...          0\n",
       "16680  This is a 100% improvement over the dross of a...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] = pd.get_dummies(df.sentiment)['positive']\n",
    "print(\"Null Values\\n\", df.isnull().sum())\n",
    "\n",
    "print(\"\\n \\t Review Balance count\\n\", Counter(df.sentiment))\n",
    "print('')\n",
    "df.sample(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bfc626",
   "metadata": {},
   "source": [
    "# 4. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "909bb4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def process_text(df,name):\n",
    "    corpus = []\n",
    "    for i,txt in enumerate(df[name]):\n",
    "        text = txt.lower()\n",
    "        text = re.sub(r'<.*?>',' ',text)\n",
    "        text = re.sub('[^a-zA-Z0-9]',' ',text)\n",
    "        df[name][i] = [lemmatizer.lemmatize(x) for x in word_tokenize(text) if x not in stop_words and len(x) > 2]\n",
    "        corpus.append(' '.join(df[name][i]))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e9d6e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = process_text(df,'review')\n",
    "total_words = len(cp)\n",
    "maxlen = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e69b3b",
   "metadata": {},
   "source": [
    "# 5. Data Splitting (Train & Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c962f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(tmp,df.sentiment,test_size=0.3,random_state=1042)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe00d1",
   "metadata": {},
   "source": [
    "# 6. Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b2ea7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(maxlen,oov_token='<OOV>',)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train,maxlen=maxlen,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c90e147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test,maxlen=maxlen,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7012e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization (TensorBoard) and early stoping\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5521f12d",
   "metadata": {},
   "source": [
    "# 7. Defining LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec0794e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=total_words,output_dim=100,input_length=maxlen,),\n",
    "    LSTM(128,dropout=0.2,name=\"Main-LSTM\",return_sequences=True),\n",
    "    LSTM(128,dropout=0.1,name='Second-Lstm'),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f8a68a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(),BinaryCrossentropy(),'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01738fb1",
   "metadata": {},
   "source": [
    "# 8. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dab12157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1094/1094 [==============================] - 47s 43ms/step - loss: 0.6515 - accuracy: 0.6055 - val_loss: 0.5597 - val_accuracy: 0.7252\n",
      "Epoch 2/20\n",
      "1094/1094 [==============================] - 43s 40ms/step - loss: 0.5472 - accuracy: 0.7217 - val_loss: 0.5268 - val_accuracy: 0.7395\n",
      "Epoch 3/20\n",
      "1094/1094 [==============================] - 43s 40ms/step - loss: 0.5298 - accuracy: 0.7354 - val_loss: 0.5209 - val_accuracy: 0.7431\n",
      "Epoch 4/20\n",
      "1094/1094 [==============================] - 43s 39ms/step - loss: 0.5220 - accuracy: 0.7376 - val_loss: 0.5151 - val_accuracy: 0.7403\n",
      "Epoch 5/20\n",
      "1094/1094 [==============================] - 121s 110ms/step - loss: 0.5153 - accuracy: 0.7419 - val_loss: 0.5103 - val_accuracy: 0.7450\n",
      "Epoch 6/20\n",
      "1094/1094 [==============================] - 41s 37ms/step - loss: 0.5090 - accuracy: 0.7465 - val_loss: 0.5214 - val_accuracy: 0.7419\n",
      "Epoch 7/20\n",
      "1094/1094 [==============================] - 41s 37ms/step - loss: 0.5030 - accuracy: 0.7500 - val_loss: 0.5040 - val_accuracy: 0.7517\n",
      "Epoch 8/20\n",
      "1094/1094 [==============================] - 41s 37ms/step - loss: 0.5212 - accuracy: 0.7380 - val_loss: 0.5115 - val_accuracy: 0.7423\n",
      "Epoch 9/20\n",
      "1094/1094 [==============================] - 42s 38ms/step - loss: 0.4994 - accuracy: 0.7516 - val_loss: 0.5067 - val_accuracy: 0.7459\n",
      "Epoch 10/20\n",
      "1094/1094 [==============================] - 41s 37ms/step - loss: 0.4935 - accuracy: 0.7557 - val_loss: 0.5044 - val_accuracy: 0.7519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21549bb8b80>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=20,validation_data=(X_test,y_test),callbacks=[tensorboard_callback,stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e77a1e",
   "metadata": {},
   "source": [
    "# 9. Testing the model with custom review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9859d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive review\n",
    "test_sent = 'This is once in a life-time movie i loved the movie must watch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b9171467",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = []\n",
    "test = test_sent.lower()\n",
    "test = re.sub(r'<.*?>',' ',test)\n",
    "test = re.sub('[^a-zA-Z0-9]',' ',test)\n",
    "test = [lemmatizer.lemmatize(x) for x in word_tokenize(test) if x not in stop_words and len(x) > 2]\n",
    "cp.append(' '.join(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8af54e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = tokenizer.texts_to_sequences(cp)\n",
    "test_ = pad_sequences(test_,maxlen=maxlen,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0249185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 29,   6,   2,   1,   2, 109,  32,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5b340211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_)\n",
    "pred = [1 if pred > 0.5 else 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0dc0d53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ==> Positive Review and 0 ==> Negative Review\n",
      "\n",
      "predicted sentiment of the review : 'This is once in a life-time movie i loved the movie must watch' is = [1]\n"
     ]
    }
   ],
   "source": [
    "print(\"1 ==> Positive Review and 0 ==> Negative Review\\n\")\n",
    "print(f\"predicted sentiment of the review : '{test_sent}' is = {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f13e6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
